## Output Format

Write findings to `/home/mk/projects/Demarch/docs/research/flux-drive/flux-drive-intermediate-findings/fd-architecture.md.partial`. Rename to `.md` when done.
Add `<!-- flux-drive:complete -->` as the last line before renaming.

ALL findings go in that file — do NOT return findings in your response text.

File structure:

### Findings Index
- P1 | A1 | "Helper Script" | `read` subcommand argument parsing bug: `$2` vs `shift`
- P1 | A2 | "Module Boundary" | `findings.jsonl` name collision with synthesis output exclusion list
- P1 | A3 | "Template Variables" | `{FINDINGS_HELPER}` and `{AGENT_NAME}` have no defined resolution path
- P1 | A4 | "Test Suite" | New shell-based test bypasses the established Python structural test suite
- P2 | A5 | "Synthesis Integration" | Synthesis step numbering gap: 3.5 injected into agent that has no step 3
- P2 | A6 | "Run Isolation" | Task 6 step 3 modifies launch.md but is described under SKILL-compact.md task
- P2 | A7 | "Template Boundary" | Peer Findings Protocol backtick block insertion is inside the prompt template string — code fences will nest
- P2 | A8 | "Concurrent Write Safety" | `>>` append is not atomic on Linux for JSONL writes over ~4KB; test 10 accepts this silently
- IMP | A9 | "YAGNI" | `fetch-findings` command adds a fourth consumer of findings-helper.sh with zero current non-debug callers
- IMP | A10 | "Naming" | `SKILL-compact.md` diverges from `launch.md` changes with no sync mechanism defined in the plan
Verdict: needs-changes

### Summary
The plan is structurally sound and well-scoped: append-only JSONL in the output directory is the right transport, no new runtime dependencies are introduced, and the synthesis integration is additive and optional. However, four P1 issues create concrete failure modes before a single line of production code runs: a shell argument parsing bug in the `read` subcommand, a name collision between `findings.jsonl` and the synthesis agent's exclusion list pattern, unresolved template variable substitution paths for two new variables, and a new test file that bypasses the project's established Python structural test suite (breaking the `test_command_count` assertion on day one). These must be fixed before implementation begins. Three P2 issues create maintenance debt or silent integration failures that are low-cost to address during the same sprint.

### Issues Found

A1. P1: `read` subcommand argument parsing bug in `findings-helper.sh` — The `read` case uses `shift` after reading `findings_file` as `$1`, then reads `filter` as `"${2:-all}"` — but after `shift`, the old `$2` is now `$1`. The filter argument will always resolve to `all` regardless of `--severity` flag. The fix is either to not shift before reading filter (`filter="${2:-all}"` before the `shift`), or to shift and then use `"${1:-all}"`. As written, `bash findings-helper.sh read file.jsonl --severity blocking` returns all findings, breaking tests 5 and 6 — which pass only because `--severity` is the argument itself being stored, not `blocking`. Evidence: plan lines 60-68, test assertions lines 419-427.

A2. P1: `findings.jsonl` collides with the synthesis agent's exclusion filter — `synthesize-review.md` step 1 excludes `summary.md`, `synthesis.md`, and `findings.json` from the agent file list via hardcoded name checks (`ls {OUTPUT_DIR}/*.md`). The new file is `findings.jsonl` (not `.md`), so the glob exclusion is fine for the `ls *.md` pass. However, `synthesize-review.md` step 8 writes `{OUTPUT_DIR}/findings.json` as a structured output. Both `findings.json` (synthesis output) and `findings.jsonl` (intermediate findings transport) now live in `OUTPUT_DIR` with nearly identical names. The synthesis agent has no instruction to skip `findings.jsonl`, and the compounding agent (synthesize.md Post-Synthesis) reads all `.md` files — this file escapes that. But future readers of `OUTPUT_DIR` contents, including any intermap or interlearn indexing, will encounter two `findings.*` files with different schemas and no discriminator. The name `findings.jsonl` should be renamed to `peer-findings.jsonl` to make ownership and schema unambiguous. Evidence: synthesize-review.md lines 23-26, 101-139; synthesize.md lines 118-149.

A3. P1: `{FINDINGS_HELPER}` and `{AGENT_NAME}` template variables have no defined resolution path — The plan introduces two new template variables into the agent prompt template in `launch.md`. The existing template variables (`{OUTPUT_DIR}`, `{REVIEW_FILE}`, `{agent-name}`, `{PROJECT_ROOT}`, etc.) are resolved by the orchestrator at dispatch time in Step 2.2 before constructing each agent's Task prompt. The plan's Task 2 Step 3 says these variables are "resolved at dispatch time when constructing each agent's prompt," but does not specify WHERE in launch.md's dispatch logic the substitution happens. `{FINDINGS_HELPER}` must resolve to `${CLAUDE_PLUGIN_ROOT}/scripts/findings-helper.sh` — which requires that `CLAUDE_PLUGIN_ROOT` is available in the orchestrator's shell context at the time the prompt string is constructed. The compact skill (SKILL-compact.md) does not define `CLAUDE_PLUGIN_ROOT` — agents are expected to reference it from within their own execution context. This creates an ambiguity: if `{FINDINGS_HELPER}` is substituted in the prompt before dispatch, the path is the orchestrator's plugin root (correct); if it is left as a literal and the agent tries to resolve it, agents do not have `CLAUDE_PLUGIN_ROOT` set in their context. The plan must specify exactly where in the orchestrator's Step 2.2 loop these two substitutions are performed, using the same pattern as existing variable resolution. Evidence: launch.md lines 281-440; plan Task 2 Steps 2-3.

A4. P1: New shell test bypasses established Python structural test suite and breaks existing assertions — The project has a `tests/structural/` suite in Python (pytest) with `test_commands.py` asserting exactly 3 commands (`assert len(files) == 3`). Task 4 adds `commands/fetch-findings.md` as a fourth command and registers it in `plugin.json`. This will cause `test_command_count` in `tests/structural/test_commands.py` (line 17) to fail immediately. Additionally, `test_expected_commands_exist` only checks for the original three. The plan creates a parallel shell test in `tests/test-findings-flow.sh` but makes no mention of updating `tests/structural/test_commands.py`. The structural tests run via `uv run pytest` and are the project's canonical correctness gate — the plan must update them. Evidence: `/home/mk/projects/Demarch/interverse/interflux/tests/structural/test_commands.py` lines 14-35; plan Task 4 Step 2.

A5. P2: Synthesis step numbering creates a documentation gap — `synthesize-review.md` uses numbered steps (1 through 8). The plan inserts "step 3.5" between steps 3 and 4. The synthesis agent is driven by an LLM reading the markdown prompt — step numbers matter for instruction ordering. "3.5" is an unusual pattern that may cause the agent to skip or reorder it. More concretely, the existing steps in synthesize-review.md are labeled `### 1.`, `### 2.`, etc. with no decimal numbering used elsewhere. The plan should renumber as step 4 and push existing steps 4-8 to 5-9, or label it `### 3b.` to match a pattern that exists in launch.md (which uses `2.1`, `2.1a`, `2.1b`, etc.). Evidence: synthesize-review.md lines 38-99; plan Task 3 Step 3.

A6. P2: Task 6 step 3 modifies `launch.md` but is scoped under the SKILL-compact.md task title — Task 6 is titled "Update Flux-Drive SKILL.md Compact Version" and Step 2 describes checking SKILL-compact.md. But Step 3 ("Add run-isolation cleanup for `findings.jsonl`") modifies the cleanup pattern in `launch.md` Step 2.0 (line 12), which is a different file. This cross-file modification buried inside a task about SKILL-compact.md will be missed during implementation: an implementor who reaches "If compact doesn't exist, this task becomes a no-op" in Step 2 may skip Steps 3-4 entirely. The isolation cleanup change in `launch.md` is necessary regardless of whether SKILL-compact.md exists and should be its own task or explicitly conditioned as "always apply, regardless of Step 2 result." Evidence: plan Task 6 Steps 2-3; launch.md lines 10-12.

A7. P2: Peer Findings Protocol contains nested backtick code fences inside the agent prompt template — The prompt template in launch.md is delimited by triple-backtick fences (lines 285 and 440). The new `## Peer Findings Protocol` section, as written in the plan, contains its own triple-backtick code blocks for the `bash` command examples. Triple-backtick blocks cannot nest inside a triple-backtick block in standard markdown renderers. When launch.md is read by an agent or rendered in Claude Code's context window, the first inner ``` terminates the outer template block prematurely. The existing prompt template works around this by using inline code spans rather than fenced blocks for its bash examples. The plan's protocol section uses full ``` fences for its two bash examples (lines 147-149 and 161-163 of the plan). These must be either indented code blocks (4-space) or use the `~~~` fence alternative that will not conflict with the outer ` ``` ` delimiters. Evidence: launch.md lines 285, 440; plan Task 2 Step 2 lines 147-163.

A8. P2: Concurrent append test accepts a race the production system will encounter — Test 10 (plan lines 454-459) forks 5 background writers and `wait`s for completion, then asserts "7 total findings." This validates that POSIX `>>` append works under concurrency. On Linux, `>>` (O_APPEND) is atomic for writes under 4096 bytes (one filesystem page), which JSONL lines comfortably fit. However, the test does not validate that the resulting JSONL is well-formed (each line is valid JSON) after concurrent writes — it only checks line count via `jq -s 'length'`. If two writes interleave at a boundary, jq will return an error rather than a count, and the `$(jq -s 'length' ...)` will produce empty output, causing the assertion to compare "7" against "" and fail with a misleading message rather than a clear "malformed JSONL" error. Add a separate assertion: `jq -s '.' "$FINDINGS" > /dev/null` before the count check to verify parse integrity. This is a low-cost addition to an existing test. Evidence: plan Task 5 lines 454-459.

### Improvements

A9. Defer `fetch-findings` command to a follow-up — The command adds a fourth file to `commands/`, requires a `plugin.json` and structural test update, adds a task in the plan, and has no current callers other than human debugging. The findings file is directly readable with `jq` or the helper script. Adding the command post-shipping (once someone actually needs it interactively) keeps this plan's diff surface minimal and avoids breaking the structural test suite as a side effect. Rationale: YAGNI — the helper script already provides the capability; the command adds ceremony without a concrete consumer.

A10. Define an explicit sync rule between `launch.md` and `SKILL-compact.md` for the Peer Findings Protocol — The compact skill delegates Phase 2 to `phases/launch.md` ("Read `phases/launch.md` for the full launch protocol") but does not enumerate the OUTPUT_DIR cleanup pattern. After Task 6 adds `findings.jsonl` to the cleanup in `launch.md`, the compact skill's cleanup description ("Clean OUTPUT_DIR of stale `.md` files before starting") will be silently incomplete. Add a one-line note in SKILL-compact.md's Phase 2 description: "findings.jsonl is also cleared on each run (see launch.md Step 2.0)." This prevents a future reader from thinking the compact skill covers the full cleanup contract. Rationale: naming drift between the two entry points is an architecture smell the CLAUDE.md explicitly flags.

--- VERDICT ---
STATUS: warn
FILES: 7 changed
FINDINGS: 10 (P0: 0, P1: 4, P2: 4)
SUMMARY: The plan's core transport design is sound, but four P1 defects — a shell argument parsing bug, a namespace collision in OUTPUT_DIR, two unresolved template variable substitution paths, and a broken structural test assertion — will produce silent failures or test suite breakage on first run. Fix these before implementation; the P2 issues are addressable in-band during each task.
---

<!-- flux-drive:complete -->
